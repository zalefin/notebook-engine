#!/usr/bin/env python3
"""
Notebook Engine
===============
Zachary Lefin
Version 3

Manage and generate html note files and compile
an index to keep track of them.
"""
import sys
from pathlib import Path
import json
from subprocess import call, Popen
import datetime
import os
import hashlib
import re
from collections import defaultdict


TIME_FORMAT = '%Y-%m-%d'
BROWSER = 'chromium'
EDITOR = 'nvim'


def get_config():
    if not os.path.isfile('./config.json'):
        print('missing config!')
        exit()

    with open('./config.json', 'r') as f:
        data = f.read()
    return json.loads(data)


def create(src_dirs):
    for i, class_name in enumerate(src_dirs):
        print(i, class_name)
    uin_name = int(input('> '))
    fname = "{}/notes/{}.md".format(src_dirs[uin_name],
            datetime.datetime.now().strftime(TIME_FORMAT))
    call([EDITOR, fname])


def compile_nb(root_dir):
    # Get all .md absolute file paths
    src_dirs = walk_src_dirs(root_dir)
    note_files = []
    types = {}
    p = re.compile(r'.*\/([^\/]+)')
    for src_dir in src_dirs:
        abs_path = src_dir + '/notes/'
        typ = p.findall(src_dir)[0]
        for f in os.listdir(abs_path):
            if str(f).endswith('.md'):
                fpath = abs_path + f
                note_files.append(fpath)
                types[fpath] = typ

    # Hash all files at paths
    current_hashes = {}
    for fp in note_files:
        with open(fp, 'rb') as f:
            dat = f.read()
        current_hashes[fp] = hashlib.sha1(dat).hexdigest()

    journal = load_journal(root_dir)

    # Difflists
    added = [fp for fp in note_files if fp not in journal.keys()]
    removed = [fp for fp in journal.keys() if fp not in note_files]
    modified = [fp for fp in note_files
            if fp in journal.keys() and current_hashes[fp] != journal[fp]]

    # Save journal to file
    with open(root_dir + '/journal.json', 'w') as f:
        f.write(json.dumps(current_hashes, indent=4))

    # Set up folder for sources
    hashpath = lambda h: '{}/.nbsrc/{}.html'.format(root_dir, h)
    if not os.path.exists(root_dir + '/.nbsrc'):
        os.mkdir(root_dir + '/.nbsrc')
    else:
        # Wipe removed src files
        rmhashes = [journal[fp] for fp in removed + modified]
        for h in rmhashes:
            hp = hashpath(h)
            try:
                os.remove(hp)
            except FileNotFoundError:
                print(hp, 'does not exist!')

    # Build list of target tuples (src path, type, hash)
    target_paths = added + modified
    build_targets = list(zip(
        target_paths,                                       # path
        map(lambda v: types[v], target_paths),              # group 
        map(lambda v: current_hashes[v], target_paths),     # hash
        ))

    # Compile targets with pandoc
    for src_path, typ, h in build_targets:
        Popen(['pandoc', src_path, '-o', hashpath(h)])

    # Get ALL links for index
    fname_pattern = re.compile(r'.*\/([^\/]+)\..+$')
    all_targets = list(zip(
        map(lambda v: fname_pattern.findall(v)[0], note_files), # name
        map(lambda v: types[v], note_files),                    # group
        map(lambda v: current_hashes[v], note_files),           # hash
        ))
    index_group_targets = defaultdict(lambda: []) # note: lambda funtion for factory
    for target in all_targets:
        index_group_targets[target[1]].append(target)

    # Compile index.html
    doc = '''
<!doctype html>
<html>
<body>
<h1>{}</h1>
{}
</body>
</html>'''
    mksec = lambda grp, targets: '''
<h2>{}</h2>
<ul>
{}
</ul>'''.format(grp,
        '\n'.join(['<li><a href="{}">{}</a></li>'.format(hashpath(h), name) for name, _, h in targets]))

    body = '\n'.join([mksec(k, v) for k, v in index_group_targets.items()])

    config = get_config()
    with open(root_dir + '/.nbsrc/index.html', 'w') as f:
        f.write(doc.format(config['title'], body))


def walk_src_dirs(root_dir):
    walker = os.walk(root_dir)
    surface_folders = next(walker)
    src_dirs = []
    for folder in walker:
        if 'notes' in folder[1]:
            src_dirs.append(folder[0])

    return src_dirs


def load_journal(root_dir):
    try:
        # create if not exists
        with open('{}/journal.json'.format(root_dir), 'x') as f:
            f.write('{}')
    except FileExistsError:
        pass

    with open('{}/journal.json'.format(root_dir), 'r') as f:
        journal = json.loads(f.read())

    return journal


def do_hooks(hooks):
    for hook in hooks:
        call(hook.split(' '))


if __name__ == "__main__":
    config = get_config()
    info = lambda: print('./nb [create|compile|open]')
    ROOT_DIR = config['root_dir']
    if len(sys.argv) > 1:
        argv = sys.argv
        if argv[1] == 'create':
            do_hooks(config['create_hooks'])
            create(walk_src_dirs(ROOT_DIR))
        elif argv[1] == 'compile':
            do_hooks(config['compile_hooks'])
            compile_nb(ROOT_DIR)
        elif argv[1] == 'open':
            Popen([BROWSER, ROOT_DIR + '/.nbsrc/index.html'], stdout=None)
        else:
            info()
    else:
        info()
        # compile_nb()
        # Popen([BROWSER, 'index.html'], stdout=None)
